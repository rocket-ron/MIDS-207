{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes in Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will again use the iris data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris target names: ['setosa' 'versicolor' 'virginica']\n",
      "Iris feature names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "# Load the data, which is included in sklearn.\n",
    "iris = load_iris()\n",
    "print 'Iris target names:', iris.target_names\n",
    "print 'Iris feature names:', iris.feature_names\n",
    "X, Y = iris.data, iris.target\n",
    "\n",
    "# Shuffle the data, but make sure that the features and accompanying labels stay in sync.\n",
    "np.random.seed(0)\n",
    "shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "X, Y = X[shuffle], Y[shuffle]\n",
    "\n",
    "# Split into train and test.\n",
    "train_data, train_labels = X[:100], Y[:100]\n",
    "test_data, test_labels = X[100:], Y[100:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a bernoulli distribution using the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a= sum(X[:])/len(X)\n",
    "X2 = X > a\n",
    "train_data2 = X2[:100]\n",
    "test_data2 = X2[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = np.median(X, axis=0)\n",
    "X2 = X > b\n",
    "train_data2 = X2[:100]\n",
    "test_data2 = X2[100:]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# using standard deviation method\n",
    "b = np.std(X, axis=0)\n",
    "X4 = abs(X - a) > b\n",
    "train_data2 = X4[:100]\n",
    "test_data2 = X4[100:] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Sklearn has three types of Naive Bayes: gaussian, beroulli, and multinomial.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\n",
    "\n",
    "What is the difference between them? These are the assumed ditributional form of each component of P(X|Y); the distribution of each individual features.\n",
    "\n",
    "Try using each of these on the iris data, you will have to prepare the data for multinomial and bernoulli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gaussian accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "gau = GaussianNB()\n",
    "gau.fit(train_data, train_labels)\n",
    "\n",
    "print 'gaussian accuracy: %3.2f' %gau.score(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bernoulli accuracy: 0.78\n"
     ]
    }
   ],
   "source": [
    "ber = BernoulliNB()\n",
    "ber.fit(train_data2, train_labels)\n",
    "\n",
    "print 'bernoulli accuracy: %3.2f' %ber.score(test_data2, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What choices did you make with manipulating the features above? Try tuning these choices, can you improve the accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate what effect alpha has on the bernoulli and multinomial classifiers. What happens when alpha is very high? Is there an optimal value?\n",
    "\n",
    "Does increasing alpha add bias or variance to our estimator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
